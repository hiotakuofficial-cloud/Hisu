VOCAB_SIZE = 50257
D_MODEL = 512
N_HEADS = 8
N_LAYERS = 6
D_FF = 2048
MAX_SEQ_LEN = 512
BATCH_SIZE = 2
GRADIENT_ACCUMULATION = 8  # Effective batch = 16
LEARNING_RATE = 3e-5
EPOCHS = 3  # Reduced from 10
DATASET_LIMIT = 1000000  # Use only 1M tokens instead of 2.4M

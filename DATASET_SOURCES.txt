================================================================================
FREE ANIME & HINDI LANGUAGE DATASETS - SOURCES AND USAGE GUIDE
================================================================================

PROJECT: 5B Parameter Anime + Hindi Multilingual Language Model
LAST UPDATED: 2026-01-02

================================================================================
1. ANIME DATASETS (CSV FORMAT)
================================================================================

KAGGLE DATASETS (Recommended - High Quality, Clean Data):
---------------------------------------------------------

1.1 MyAnimeList Dataset (2023)
   URL: https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset
   Size: ~14 MB
   Records: 21,460+ anime entries
   Columns: 28 distinct columns
   Features: anime_id, title, genre, type, episodes, rating, members, synopsis,
            aired dates, studios, etc.
   Quality: Clean, well-structured
   Download: kaggle datasets download -d dbdmobile/myanimelist-dataset

1.2 MyAnimeList Dataset (Alternative)
   URL: https://www.kaggle.com/datasets/svanoo/myanimelist-dataset
   Features: Similar to above with different time range
   Download: kaggle datasets download -d svanoo/myanimelist-dataset

1.3 Manga & Anime Dataset 2024
   URL: https://www.kaggle.com/datasets/duongtruongbinh/manga-and-anime-dataset
   Features: Combined manga and anime information
   Quality: Up-to-date as of 2024
   Download: kaggle datasets download -d duongtruongbinh/manga-and-anime-dataset

1.4 Anime Recommendations Database
   URL: https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database
   Features: Includes user ratings and recommendations
   Size: 300k+ users, 14k+ anime, 80M+ ratings
   Perfect for: Recommendation systems
   Download: kaggle datasets download -d CooperUnion/anime-recommendations-database

1.5 Anime Dataset with Reviews
   URL: https://www.kaggle.com/datasets/marlesson/myanimelist-dataset-animes-profiles-reviews
   Features: Anime metadata + user reviews + profiles
   Perfect for: Sentiment analysis and review-based training
   Download: kaggle datasets download -d marlesson/myanimelist-dataset-animes-profiles-reviews


OPEN DATA MARKETPLACE (Direct CSV Downloads):
---------------------------------------------

1.6 Anime Statistics & Trends Dataset
   URL: https://www.opendatabay.com/data/consumer/9d2912e3-a965-47ce-b215-44cb291146e5
   Format: CSV (Anime.csv)
   Size: 14.22 MB
   Records: 21,460 entries
   Columns: 28 columns
   Quality: 100% valid entries, high quality
   Scraped: September 2022

1.7 Global Anime Catalogue Dataset
   URL: https://www.opendatabay.com/data/web-social/30fbf799-7e31-41d9-89fe-2f9b90d7f1b4
   Format: CSV
   Size: 1.35 MB
   Records: 1,563 entries
   Columns: 20 columns

1.8 Anime Popularity and Score Trends
   URL: https://www.opendatabay.com/data/ai-ml/f8bb5eb9-d9fb-47ee-8c44-037811e0fb29
   Format: CSV
   Features: Time-series data for trends analysis


GITHUB REPOSITORIES:
-------------------

1.9 MyAnimeList Database (GitHub)
   URL: https://github.com/Hernan4444/MyAnimeList-Database
   Features: Regularly updated scraper and datasets
   Format: CSV exports available


================================================================================
2. HINDI LANGUAGE DATASETS (NLP/TRANSLATION)
================================================================================

PARALLEL CORPORA (English-Hindi):
---------------------------------

2.1 IIT Bombay English-Hindi Parallel Corpus ⭐ RECOMMENDED
   Official URL: https://www.cfilt.iitb.ac.in/iitb_parallel/
   HuggingFace: https://huggingface.co/datasets/cfilt/iitb-english-hindi
   Size: 1.49M parallel sentences
   Quality: High quality, curated by IIT Bombay
   Format: Available in CSV/TSV formats
   Features: Multiple domains (news, literature, technical)

   Download via HuggingFace:
   ```python
   from datasets import load_dataset
   dataset = load_dataset("cfilt/iitb-english-hindi")
   # Export to CSV
   dataset['train'].to_csv('iitb_hindi_english.csv')
   ```

2.2 AI4Bharat Samanantar Corpus ⭐ LARGEST
   URL: https://ai4bharat.iitm.ac.in/samanantar
   GitHub: https://github.com/AI4Bharat/indicnlp_catalog
   Size: 46 MILLION parallel sentences (English + 11 Indian languages)
   Hindi Subset: ~10M+ sentence pairs
   Quality: Largest publicly available corpus
   Format: CSV/JSON

   Download:
   ```bash
   # Available through AI4Bharat repository
   wget https://ai4bharat-public-indic-nlp-corpora.s3.us-east-2.amazonaws.com/
   ```

2.3 BPCC (Bharat Parallel Corpus Collection)
   Size: 230 MILLION sentence pairs
   Languages: English + 22 Indian languages
   Hindi Subset: ~50M+ pairs
   Quality: Comprehensive, multiple domains
   Status: As of Jan 2024 - Largest available

2.4 WAT 2019 Hindi-English Dataset
   URL: Available through WAT (Workshop on Asian Translation)
   Records: 32,925 multimodal entries
   Features: Image + Region + English + Hindi caption
   Format: Text + JPEG
   Perfect for: Multimodal learning

2.5 IndicNLP Catalog (AI4Bharat)
   GitHub: https://github.com/AI4Bharat/indicnlp_catalog
   Features: Comprehensive collection of Indic language resources
   Includes: WAT 2021 Translation datasets (English + 10 Indian languages)


CONVERSATIONAL DATASETS:
------------------------

2.6 Hindi Conversational Datasets
   Sources: Multiple repositories on HuggingFace
   - ai4bharat/IndicQA (Question-Answering in Hindi)
   - Hindi Wikipedia dumps (Conversational extracts)
   - Dakshina dataset (Romanized Hindi + Native script)


================================================================================
3. USAGE INSTRUCTIONS
================================================================================

SETUP KAGGLE API:
-----------------
1. Install: pip install kaggle
2. Get API token: kaggle.com -> Account -> Create New API Token
3. Place kaggle.json in ~/.kaggle/ (Linux/Mac) or C:\Users\<username>\.kaggle\ (Windows)
4. Download datasets using commands above


SETUP HUGGINGFACE:
-----------------
1. Install: pip install datasets
2. Use code snippets above to download
3. Export to CSV for integration with our pipeline


INTEGRATION WITH OUR PROJECT:
-----------------------------

Directory Structure:
-------------------
data/
├── raw/                          # Raw downloaded datasets
│   ├── anime_dataset.csv
│   ├── hindi_translation_dataset.csv
│   ├── iitb_parallel_corpus.csv
│   └── samanantar_hindi_en.csv
├── processed/                    # Processed datasets
└── checkpoints/                  # Model checkpoints

Usage in Code:
-------------
```python
from src.data.dataset_downloader import DatasetDownloader

# Initialize downloader
downloader = DatasetDownloader(cache_dir="data/raw")

# Load datasets
anime_df = downloader.load_anime_dataset()
hindi_df = downloader.load_hindi_dataset()

# Or download directly
# Place downloaded CSV in data/raw/
# Update paths in config
```


================================================================================
4. DATA QUALITY NOTES
================================================================================

ANIME DATASETS:
--------------
✓ MyAnimeList datasets are the gold standard (most complete, regularly updated)
✓ Look for datasets with 20k+ entries for comprehensive coverage
✓ Ensure columns include: title, genre, synopsis, rating, episodes
✓ Check for null values in critical fields (genre, synopsis)
✓ Some datasets include user reviews - valuable for sentiment analysis

HINDI DATASETS:
--------------
✓ IIT Bombay corpus - Best quality, academically curated
✓ Samanantar - Best for scale, 46M+ sentences
✓ BPCC - Most comprehensive, 230M+ sentences
✓ Ensure proper Devanagari encoding (UTF-8)
✓ Look for domain-specific corpora if needed (technical, conversational, etc.)


================================================================================
5. MODEL TRAINING RECOMMENDATIONS
================================================================================

DATA PREPROCESSING:
------------------
1. Clean text: Remove HTML, special characters
2. Normalize: Lowercase English, preserve Devanagari
3. Tokenization: Use our MultilingualTokenizer for Hindi+English
4. Augmentation: Back-translation, synonym replacement
5. Balance: Ensure equal representation of Hindi/English examples

TRAINING STRATEGY:
-----------------
1. Pre-training: Large general corpus (Samanantar)
2. Fine-tuning: Anime-specific corpus (MyAnimeList)
3. Task-specific: Conversational examples
4. Multilingual mixing: 50% Hindi, 50% English during training
5. Continuous learning: Regular updates with new anime releases


================================================================================
6. LICENSE AND ATTRIBUTION
================================================================================

Most datasets are released under:
- Creative Commons (CC BY-SA)
- MIT License
- Academic use permitted

ATTRIBUTION REQUIRED:
--------------------
- IIT Bombay Corpus: Cite CFILT, IIT Bombay
- AI4Bharat datasets: Cite AI4Bharat, IIT Madras
- Kaggle datasets: Check individual dataset licenses
- Always credit original scrapers/creators


================================================================================
7. DOWNLOAD COMMANDS SUMMARY
================================================================================

# Anime Datasets (Kaggle)
kaggle datasets download -d dbdmobile/myanimelist-dataset
kaggle datasets download -d CooperUnion/anime-recommendations-database
kaggle datasets download -d duongtruongbinh/manga-and-anime-dataset

# Hindi Datasets (HuggingFace)
from datasets import load_dataset
iitb = load_dataset("cfilt/iitb-english-hindi")
iitb['train'].to_csv('data/raw/iitb_parallel_corpus.csv')

# Extract and place in data/raw/
# Run our training pipeline: python anime_hindi_chatbot.py


================================================================================
END OF DATASET SOURCES GUIDE
================================================================================

For questions or issues:
- Check dataset documentation links above
- Verify API tokens are configured
- Ensure proper file permissions
- Check disk space (some datasets are large)

Total Available Data:
- Anime: 300k+ entries across all sources
- Hindi-English: 50M+ parallel sentences
- Quality: Academic and community-curated

PERFECT FOR: 5B parameter multilingual anime language model training!
================================================================================
